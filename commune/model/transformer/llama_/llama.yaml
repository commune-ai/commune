vocab_size: 32000
hidden_size: 4096
intermediate_size: 11008
num_hidden_layers: 32
num_attention_heads: 32
hidden_act: "silu"
max_position_embeddings: 2048
initializer_range: 0.02
rms_norm_eps: 1e-6
use_cache: true
pad_token_id: 0
bos_token_id: 1
eos_token_id: 2
tie_word_embeddings: false
